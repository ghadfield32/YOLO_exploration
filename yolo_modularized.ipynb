{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting modularized/setup_and_installation.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile modularized/setup_and_installation.py\n",
    "import subprocess\n",
    "\n",
    "def setup_and_install():\n",
    "    # Install necessary packages\n",
    "    packages = [\n",
    "        \"git+https://github.com/THU-MIG/yolov10.git\",\n",
    "        \"supervision\",\n",
    "        \"roboflow\"\n",
    "    ]\n",
    "\n",
    "    for package in packages:\n",
    "        subprocess.run([\"pip\", \"install\", package], check=True)\n",
    "\n",
    "    print(\"Setup and installation complete.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting modularized/download_weights.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile modularized/download_weights.py\n",
    "import os\n",
    "import requests\n",
    "\n",
    "def download_weights():\n",
    "    weights_dir = os.path.join(\"weights\")\n",
    "    os.makedirs(weights_dir, exist_ok=True)\n",
    "\n",
    "    weights_urls = [\n",
    "        \"https://github.com/jameslahm/yolov10/releases/download/v1.0/yolov10n.pt\",\n",
    "        \"https://github.com/jameslahm/yolov10/releases/download/v1.0/yolov10s.pt\",\n",
    "        \"https://github.com/jameslahm/yolov10/releases/download/v1.0/yolov10m.pt\",\n",
    "        \"https://github.com/jameslahm/yolov10/releases/download/v1.0/yolov10b.pt\",\n",
    "        \"https://github.com/jameslahm/yolov10/releases/download/v1.0/yolov10x.pt\",\n",
    "        \"https://github.com/jameslahm/yolov10/releases/download/v1.0/yolov10l.pt\"\n",
    "    ]\n",
    "\n",
    "    def download_file(url, dest_folder):\n",
    "        filename = os.path.join(dest_folder, url.split('/')[-1])\n",
    "        if not os.path.exists(filename):\n",
    "            with requests.get(url, stream=True) as r:\n",
    "                r.raise_for_status()\n",
    "                with open(filename, 'wb') as f:\n",
    "                    for chunk in r.iter_content(chunk_size=8192):\n",
    "                        f.write(chunk)\n",
    "            print(f\"Downloaded: {filename}\")\n",
    "        else:\n",
    "            print(f\"File already exists: {filename}\")\n",
    "\n",
    "    for url in weights_urls:\n",
    "        download_file(url, weights_dir)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting modularized/initialize_model.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile modularized/initialize_model.py\n",
    "import torch\n",
    "from ultralytics import YOLOv10\n",
    "import os\n",
    "\n",
    "def initialize_model(weights_dir):\n",
    "    print(torch.__version__)\n",
    "    print(\"CUDA available: \", torch.cuda.is_available())\n",
    "    device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "    print(f\"Using device: {device}\")\n",
    "\n",
    "    model = YOLOv10(os.path.join(weights_dir, \"yolov10n.pt\"))\n",
    "    print(\"yolov10 preset classes = \", model.names)\n",
    "    return model, device\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting modularized/download_dataset.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile modularized/download_dataset.py\n",
    "import yaml\n",
    "from roboflow import Roboflow\n",
    "import os\n",
    "\n",
    "def download_dataset():\n",
    "    rf = Roboflow(api_key=\"YOUR_API_KEY\")\n",
    "    project = rf.workspace(\"basketball-formations\").project(\"basketball-and-hoop-7xk0h\")\n",
    "    version = project.version(11)\n",
    "    dataset = version.download(\"yolov8\")\n",
    "\n",
    "    dataset_location = dataset.location\n",
    "    data_yaml_path = os.path.join(dataset_location, \"data.yaml\")\n",
    "\n",
    "    with open(data_yaml_path, 'r') as file:\n",
    "        data_yaml = yaml.safe_load(file)\n",
    "    data_yaml['train'] = '../train/images'\n",
    "    data_yaml['val'] = '../valid/images'\n",
    "    with open(data_yaml_path, 'w') as file:\n",
    "        yaml.safe_dump(data_yaml, file)\n",
    "\n",
    "    class_names = data_yaml['names']\n",
    "    print(\"my roboflow classes = \", class_names)\n",
    "    return dataset_location, data_yaml_path, class_names\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting modularized/inference_pretrained.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile modularized/inference_pretrained.py\n",
    "import cv2\n",
    "import supervision as sv\n",
    "\n",
    "def inference_pretrained(model, image_path):\n",
    "    image = cv2.imread(image_path)\n",
    "    results = model(image)[0]\n",
    "    detections = sv.Detections.from_ultralytics(results)\n",
    "\n",
    "    bounding_box_annotator = sv.BoundingBoxAnnotator()\n",
    "    label_annotator = sv.LabelAnnotator()\n",
    "    annotated_image = bounding_box_annotator.annotate(scene=image, detections=detections)\n",
    "    annotated_image = label_annotator.annotate(scene=annotated_image, detections=detections)\n",
    "    sv.plot_image(annotated_image)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting modularized/custom_training.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile modularized/custom_training.py\n",
    "import os\n",
    "import shutil\n",
    "\n",
    "def custom_training(weights_dir, data_yaml_path, device, epochs, batch_size):\n",
    "    runs_dir = os.path.join(\"runs\")\n",
    "    if os.path.exists(runs_dir):\n",
    "        shutil.rmtree(runs_dir)\n",
    "        print(f\"Removed previous run files in {runs_dir}\")\n",
    "\n",
    "    os.system(f'yolo task=detect mode=train epochs={epochs} batch={batch_size} plots=True model={os.path.join(weights_dir, \"yolov10x.pt\")} data={data_yaml_path} device={device}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting modularized/post_training_results.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile modularized/post_training_results.py\n",
    "import os\n",
    "from IPython.display import display, Image\n",
    "\n",
    "def post_training_results():\n",
    "    results_dir = os.path.join(\"runs\", \"detect\", \"train\")\n",
    "    best_model_path = os.path.join(results_dir, \"weights\", \"best.pt\")\n",
    "    if os.path.exists(results_dir):\n",
    "        display(Image(filename=os.path.join(results_dir, \"confusion_matrix.png\"), width=600))\n",
    "        display(Image(filename=os.path.join(results_dir, \"results.png\"), width=600))\n",
    "        \n",
    "        print(\"Trained model files:\")\n",
    "        for file_name in os.listdir(os.path.join(results_dir, \"weights\")):\n",
    "            if file_name.endswith(\".pt\"):\n",
    "                print(file_name)\n",
    "    return best_model_path\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting modularized/download_video.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile modularized/download_video.py\n",
    "import os\n",
    "from pytube import YouTube\n",
    "from moviepy.video.io.ffmpeg_tools import ffmpeg_extract_subclip\n",
    "from moviepy.editor import VideoFileClip\n",
    "\n",
    "def download_video(yt_video_url):\n",
    "    HOME = os.getcwd()\n",
    "    video_path = os.path.join(HOME, 'hq_luka.mp4')\n",
    "\n",
    "    yt = YouTube(yt_video_url)\n",
    "\n",
    "    print(\"Available streams:\")\n",
    "    for stream in yt.streams.filter(progressive=True, file_extension='mp4').order_by('resolution'):\n",
    "        print(stream)\n",
    "\n",
    "    stream = yt.streams.filter(progressive=True, file_extension='mp4').order_by('resolution').desc().first()\n",
    "    stream.download(output_path=HOME, filename='hq_luka.mp4')\n",
    "    print(f\"Downloaded video: {video_path}\")\n",
    "\n",
    "    video = VideoFileClip(video_path)\n",
    "    duration = video.duration\n",
    "\n",
    "    start_time = 174  # 2 minutes and 54 seconds\n",
    "    output_path = os.path.join(HOME, 'hq_luka_cut.mp4')\n",
    "\n",
    "    ffmpeg_extract_subclip(video_path, start_time, duration, targetname=output_path)\n",
    "    print(f\"Cut video saved to: {output_path}\")\n",
    "    return output_path\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting modularized/object_tracking_scoring.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile modularized/object_tracking_scoring.py\n",
    "import os\n",
    "import cv2\n",
    "import supervision as sv\n",
    "from ultralytics import YOLOv10\n",
    "import numpy as np\n",
    "\n",
    "def object_tracking_scoring(video_path, best_model_path):\n",
    "    # Load the best trained model\n",
    "    trained_model = YOLOv10(best_model_path)\n",
    "    \n",
    "    # Initialize trackers and annotators\n",
    "    tracker = sv.ByteTrack()\n",
    "    bounding_box_annotator = sv.BoundingBoxAnnotator()\n",
    "    label_annotator = sv.LabelAnnotator()\n",
    "    trace_annotator = sv.TraceAnnotator()\n",
    "\n",
    "    # Initialize score and intersection tracking\n",
    "    score = 0\n",
    "    intersected_basketballs = set()\n",
    "\n",
    "    # Function to check intersection\n",
    "    def check_intersection(basketball_box, hoop_box):\n",
    "        x1_b, y1_b, x2_b, y2_b = basketball_box\n",
    "        x1_h, y1_h, x2_h, y2_h = hoop_box\n",
    "        \n",
    "        # Check if the boxes intersect\n",
    "        if x1_b < x2_h and x2_b > x1_h and y1_b < y2_h and y2_b > y1_h:\n",
    "            return True\n",
    "        return False\n",
    "\n",
    "    # Callback function for processing each frame\n",
    "    def callback(frame: np.ndarray, _: int) -> np.ndarray:\n",
    "        nonlocal score, intersected_basketballs\n",
    "        results = trained_model(frame)\n",
    "        print(\"Results type:\", type(results))\n",
    "        print(\"Results:\", results)\n",
    "        \n",
    "        # Extract results from the list\n",
    "        results = results[0]\n",
    "        \n",
    "        # Convert the results to Detections\n",
    "        detections = sv.Detections.from_ultralytics(results)\n",
    "        \n",
    "        # Update detections with tracker\n",
    "        detections = tracker.update_with_detections(detections)\n",
    "        \n",
    "        # Generate labels\n",
    "        labels = [\n",
    "            f\"#{tracker_id} {trained_model.names[class_id]}\"\n",
    "            for class_id, tracker_id in zip(detections.class_id, detections.tracker_id)\n",
    "        ]\n",
    "        \n",
    "        # Ensure that labels list matches the number of detections\n",
    "        if len(labels) != len(detections):\n",
    "            print(f\"Warning: Number of labels ({len(labels)}) does not match number of detections ({len(detections)})\")\n",
    "            return frame  # Return the original frame if there's a mismatch\n",
    "\n",
    "        # Get bounding boxes and tracker IDs for basketball and hoop\n",
    "        basketball_boxes = [(box, tracker_id) for box, class_id, tracker_id in zip(detections.xyxy, detections.class_id, detections.tracker_id) if class_id == 1]\n",
    "        hoop_boxes = [(box, tracker_id) for box, class_id, tracker_id in zip(detections.xyxy, detections.class_id, detections.tracker_id) if class_id == 2]\n",
    "        \n",
    "        # Check for intersection and update score\n",
    "        for basketball_box, basketball_id in basketball_boxes:\n",
    "            for hoop_box, hoop_id in hoop_boxes:\n",
    "                if check_intersection(basketball_box, hoop_box):\n",
    "                    if basketball_id not in intersected_basketballs:\n",
    "                        score += 1\n",
    "                        intersected_basketballs.add(basketball_id)\n",
    "\n",
    "        # Annotate frame with bounding boxes and labels\n",
    "        annotated_frame = bounding_box_annotator.annotate(frame.copy(), detections=detections)\n",
    "        annotated_frame = label_annotator.annotate(annotated_frame, detections=detections, labels=labels)\n",
    "\n",
    "        # Overlay the score on the frame\n",
    "        cv2.putText(annotated_frame, f\"Score: {score}\", (10, 50), cv2.FONT_HERSHEY_SIMPLEX, 1, (255, 0, 0), 2, cv2.LINE_AA)\n",
    "        \n",
    "        return trace_annotator.annotate(annotated_frame, detections=detections)\n",
    "\n",
    "    # Process video with tracking and scoring using the updated callback\n",
    "    sv.process_video(source_path=video_path, target_path=os.path.join(\"result.mp4\"), callback=callback)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing main.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile main.py\n",
    "import argparse\n",
    "from modularized.setup_and_installation import setup_and_install\n",
    "from modularized.download_weights import download_weights\n",
    "from modularized.initialize_model import initialize_model\n",
    "from modularized.download_dataset import download_dataset\n",
    "from modularized.inference_pretrained import inference_pretrained\n",
    "from modularized.custom_training import custom_training\n",
    "from modularized.post_training_results import post_training_results\n",
    "from modularized.download_video import download_video\n",
    "from modularized.object_tracking_scoring import object_tracking_scoring\n",
    "\n",
    "def main(args):\n",
    "    # Setup and Installation\n",
    "    setup_and_install()\n",
    "    \n",
    "    # Download YOLOv10 Weights\n",
    "    download_weights()\n",
    "    \n",
    "    # Initialize YOLOv10 Model\n",
    "    weights_dir = \"weights\"\n",
    "    model, device = initialize_model(weights_dir)\n",
    "    \n",
    "    # Download Dataset from Roboflow\n",
    "    dataset_location, data_yaml_path, class_names = download_dataset()\n",
    "    \n",
    "    # Inference with Pre-trained Model\n",
    "    inference_pretrained(model, args.image_path)\n",
    "    \n",
    "    # Custom Training\n",
    "    custom_training(weights_dir, data_yaml_path, device, args.epochs, args.batch_size)\n",
    "    \n",
    "    # Post-training Results and Visualization\n",
    "    best_model_path = post_training_results()\n",
    "    \n",
    "    # Download High-Quality Video from YouTube\n",
    "    video_path = download_video(args.yt_video_url)\n",
    "    \n",
    "    # Object Tracking and Scoring\n",
    "    object_tracking_scoring(video_path, best_model_path)\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    parser = argparse.ArgumentParser(description=\"YOLOv10 Training and Inference Pipeline\")\n",
    "    parser.add_argument(\"--epochs\", type=int, default=25, help=\"Number of epochs for training\")\n",
    "    parser.add_argument(\"--batch_size\", type=int, default=8, help=\"Batch size for training\")\n",
    "    parser.add_argument(\"--image_path\", type=str, default=\"your_image.png\", help=\"Path to the image for inference\")\n",
    "    parser.add_argument(\"--yt_video_url\", type=str, default=\"https://www.youtube.com/watch?v=KyC6wr4I2VU\", help=\"URL of the YouTube video for object tracking and scoring\")\n",
    "    args = parser.parse_args()\n",
    "    main(args)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting git+https://github.com/THU-MIG/yolov10.git\n",
      "  Cloning https://github.com/THU-MIG/yolov10.git to c:\\users\\ghadf\\appdata\\local\\temp\\pip-req-build-k47tvxov\n",
      "  Resolved https://github.com/THU-MIG/yolov10.git to commit d8777c1449509366ef3fa4892afab9b6f2880dbf\n",
      "  Installing build dependencies: started\n",
      "  Installing build dependencies: finished with status 'done'\n",
      "  Getting requirements to build wheel: started\n",
      "  Getting requirements to build wheel: finished with status 'done'\n",
      "  Preparing metadata (pyproject.toml): started\n",
      "  Preparing metadata (pyproject.toml): finished with status 'done'\n",
      "Requirement already satisfied: matplotlib>=3.3.0 in c:\\users\\ghadf\\vscode_projects\\venv_projects\\pytorch\\yolo_exploration\\.venv\\lib\\site-packages (from ultralytics==8.1.34) (3.9.0)\n",
      "Requirement already satisfied: opencv-python>=4.6.0 in c:\\users\\ghadf\\vscode_projects\\venv_projects\\pytorch\\yolo_exploration\\.venv\\lib\\site-packages (from ultralytics==8.1.34) (4.9.0.80)\n",
      "Requirement already satisfied: pillow>=7.1.2 in c:\\users\\ghadf\\vscode_projects\\venv_projects\\pytorch\\yolo_exploration\\.venv\\lib\\site-packages (from ultralytics==8.1.34) (10.3.0)\n",
      "Requirement already satisfied: pyyaml>=5.3.1 in c:\\users\\ghadf\\vscode_projects\\venv_projects\\pytorch\\yolo_exploration\\.venv\\lib\\site-packages (from ultralytics==8.1.34) (6.0.1)\n",
      "Requirement already satisfied: requests>=2.23.0 in c:\\users\\ghadf\\vscode_projects\\venv_projects\\pytorch\\yolo_exploration\\.venv\\lib\\site-packages (from ultralytics==8.1.34) (2.32.2)\n",
      "Requirement already satisfied: scipy>=1.4.1 in c:\\users\\ghadf\\vscode_projects\\venv_projects\\pytorch\\yolo_exploration\\.venv\\lib\\site-packages (from ultralytics==8.1.34) (1.13.1)\n",
      "Requirement already satisfied: torch>=1.8.0 in c:\\users\\ghadf\\vscode_projects\\venv_projects\\pytorch\\yolo_exploration\\.venv\\lib\\site-packages (from ultralytics==8.1.34) (2.3.1+cu121)\n",
      "Requirement already satisfied: torchvision>=0.9.0 in c:\\users\\ghadf\\vscode_projects\\venv_projects\\pytorch\\yolo_exploration\\.venv\\lib\\site-packages (from ultralytics==8.1.34) (0.18.1+cu121)\n",
      "Requirement already satisfied: tqdm>=4.64.0 in c:\\users\\ghadf\\vscode_projects\\venv_projects\\pytorch\\yolo_exploration\\.venv\\lib\\site-packages (from ultralytics==8.1.34) (4.66.4)\n",
      "Requirement already satisfied: psutil in c:\\users\\ghadf\\vscode_projects\\venv_projects\\pytorch\\yolo_exploration\\.venv\\lib\\site-packages (from ultralytics==8.1.34) (5.9.8)\n",
      "Requirement already satisfied: py-cpuinfo in c:\\users\\ghadf\\vscode_projects\\venv_projects\\pytorch\\yolo_exploration\\.venv\\lib\\site-packages (from ultralytics==8.1.34) (9.0.0)\n",
      "Requirement already satisfied: thop>=0.1.1 in c:\\users\\ghadf\\vscode_projects\\venv_projects\\pytorch\\yolo_exploration\\.venv\\lib\\site-packages (from ultralytics==8.1.34) (0.1.1.post2209072238)\n",
      "Requirement already satisfied: pandas>=1.1.4 in c:\\users\\ghadf\\vscode_projects\\venv_projects\\pytorch\\yolo_exploration\\.venv\\lib\\site-packages (from ultralytics==8.1.34) (2.2.2)\n",
      "Requirement already satisfied: seaborn>=0.11.0 in c:\\users\\ghadf\\vscode_projects\\venv_projects\\pytorch\\yolo_exploration\\.venv\\lib\\site-packages (from ultralytics==8.1.34) (0.13.2)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in c:\\users\\ghadf\\vscode_projects\\venv_projects\\pytorch\\yolo_exploration\\.venv\\lib\\site-packages (from matplotlib>=3.3.0->ultralytics==8.1.34) (1.2.1)\n",
      "Requirement already satisfied: cycler>=0.10 in c:\\users\\ghadf\\vscode_projects\\venv_projects\\pytorch\\yolo_exploration\\.venv\\lib\\site-packages (from matplotlib>=3.3.0->ultralytics==8.1.34) (0.10.0)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in c:\\users\\ghadf\\vscode_projects\\venv_projects\\pytorch\\yolo_exploration\\.venv\\lib\\site-packages (from matplotlib>=3.3.0->ultralytics==8.1.34) (4.52.1)\n",
      "Requirement already satisfied: kiwisolver>=1.3.1 in c:\\users\\ghadf\\vscode_projects\\venv_projects\\pytorch\\yolo_exploration\\.venv\\lib\\site-packages (from matplotlib>=3.3.0->ultralytics==8.1.34) (1.4.5)\n",
      "Requirement already satisfied: numpy>=1.23 in c:\\users\\ghadf\\vscode_projects\\venv_projects\\pytorch\\yolo_exploration\\.venv\\lib\\site-packages (from matplotlib>=3.3.0->ultralytics==8.1.34) (1.26.4)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\users\\ghadf\\vscode_projects\\venv_projects\\pytorch\\yolo_exploration\\.venv\\lib\\site-packages (from matplotlib>=3.3.0->ultralytics==8.1.34) (24.0)\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in c:\\users\\ghadf\\vscode_projects\\venv_projects\\pytorch\\yolo_exploration\\.venv\\lib\\site-packages (from matplotlib>=3.3.0->ultralytics==8.1.34) (3.1.2)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in c:\\users\\ghadf\\vscode_projects\\venv_projects\\pytorch\\yolo_exploration\\.venv\\lib\\site-packages (from matplotlib>=3.3.0->ultralytics==8.1.34) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\users\\ghadf\\vscode_projects\\venv_projects\\pytorch\\yolo_exploration\\.venv\\lib\\site-packages (from pandas>=1.1.4->ultralytics==8.1.34) (2024.1)\n",
      "Requirement already satisfied: tzdata>=2022.7 in c:\\users\\ghadf\\vscode_projects\\venv_projects\\pytorch\\yolo_exploration\\.venv\\lib\\site-packages (from pandas>=1.1.4->ultralytics==8.1.34) (2024.1)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\ghadf\\vscode_projects\\venv_projects\\pytorch\\yolo_exploration\\.venv\\lib\\site-packages (from requests>=2.23.0->ultralytics==8.1.34) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\ghadf\\vscode_projects\\venv_projects\\pytorch\\yolo_exploration\\.venv\\lib\\site-packages (from requests>=2.23.0->ultralytics==8.1.34) (2.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\ghadf\\vscode_projects\\venv_projects\\pytorch\\yolo_exploration\\.venv\\lib\\site-packages (from requests>=2.23.0->ultralytics==8.1.34) (2.2.1)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\ghadf\\vscode_projects\\venv_projects\\pytorch\\yolo_exploration\\.venv\\lib\\site-packages (from requests>=2.23.0->ultralytics==8.1.34) (2023.7.22)\n",
      "Requirement already satisfied: filelock in c:\\users\\ghadf\\vscode_projects\\venv_projects\\pytorch\\yolo_exploration\\.venv\\lib\\site-packages (from torch>=1.8.0->ultralytics==8.1.34) (3.14.0)\n",
      "Requirement already satisfied: typing-extensions>=4.8.0 in c:\\users\\ghadf\\vscode_projects\\venv_projects\\pytorch\\yolo_exploration\\.venv\\lib\\site-packages (from torch>=1.8.0->ultralytics==8.1.34) (4.12.0)\n",
      "Requirement already satisfied: sympy in c:\\users\\ghadf\\vscode_projects\\venv_projects\\pytorch\\yolo_exploration\\.venv\\lib\\site-packages (from torch>=1.8.0->ultralytics==8.1.34) (1.12)\n",
      "Requirement already satisfied: networkx in c:\\users\\ghadf\\vscode_projects\\venv_projects\\pytorch\\yolo_exploration\\.venv\\lib\\site-packages (from torch>=1.8.0->ultralytics==8.1.34) (3.3)\n",
      "Requirement already satisfied: jinja2 in c:\\users\\ghadf\\vscode_projects\\venv_projects\\pytorch\\yolo_exploration\\.venv\\lib\\site-packages (from torch>=1.8.0->ultralytics==8.1.34) (3.1.4)\n",
      "Requirement already satisfied: fsspec in c:\\users\\ghadf\\vscode_projects\\venv_projects\\pytorch\\yolo_exploration\\.venv\\lib\\site-packages (from torch>=1.8.0->ultralytics==8.1.34) (2024.5.0)\n",
      "Requirement already satisfied: mkl<=2021.4.0,>=2021.1.1 in c:\\users\\ghadf\\vscode_projects\\venv_projects\\pytorch\\yolo_exploration\\.venv\\lib\\site-packages (from torch>=1.8.0->ultralytics==8.1.34) (2021.4.0)\n",
      "Requirement already satisfied: colorama in c:\\users\\ghadf\\vscode_projects\\venv_projects\\pytorch\\yolo_exploration\\.venv\\lib\\site-packages (from tqdm>=4.64.0->ultralytics==8.1.34) (0.4.6)\n",
      "Requirement already satisfied: six in c:\\users\\ghadf\\vscode_projects\\venv_projects\\pytorch\\yolo_exploration\\.venv\\lib\\site-packages (from cycler>=0.10->matplotlib>=3.3.0->ultralytics==8.1.34) (1.16.0)\n",
      "Requirement already satisfied: intel-openmp==2021.* in c:\\users\\ghadf\\vscode_projects\\venv_projects\\pytorch\\yolo_exploration\\.venv\\lib\\site-packages (from mkl<=2021.4.0,>=2021.1.1->torch>=1.8.0->ultralytics==8.1.34) (2021.4.0)\n",
      "Requirement already satisfied: tbb==2021.* in c:\\users\\ghadf\\vscode_projects\\venv_projects\\pytorch\\yolo_exploration\\.venv\\lib\\site-packages (from mkl<=2021.4.0,>=2021.1.1->torch>=1.8.0->ultralytics==8.1.34) (2021.12.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in c:\\users\\ghadf\\vscode_projects\\venv_projects\\pytorch\\yolo_exploration\\.venv\\lib\\site-packages (from jinja2->torch>=1.8.0->ultralytics==8.1.34) (2.1.5)\n",
      "Requirement already satisfied: mpmath>=0.19 in c:\\users\\ghadf\\vscode_projects\\venv_projects\\pytorch\\yolo_exploration\\.venv\\lib\\site-packages (from sympy->torch>=1.8.0->ultralytics==8.1.34) (1.3.0)\n",
      "Requirement already satisfied: supervision in c:\\users\\ghadf\\vscode_projects\\venv_projects\\pytorch\\yolo_exploration\\.venv\\lib\\site-packages (0.21.0)\n",
      "Requirement already satisfied: defusedxml<0.8.0,>=0.7.1 in c:\\users\\ghadf\\vscode_projects\\venv_projects\\pytorch\\yolo_exploration\\.venv\\lib\\site-packages (from supervision) (0.7.1)\n",
      "Requirement already satisfied: matplotlib>=3.6.0 in c:\\users\\ghadf\\vscode_projects\\venv_projects\\pytorch\\yolo_exploration\\.venv\\lib\\site-packages (from supervision) (3.9.0)\n",
      "Requirement already satisfied: numpy>=1.21.2 in c:\\users\\ghadf\\vscode_projects\\venv_projects\\pytorch\\yolo_exploration\\.venv\\lib\\site-packages (from supervision) (1.26.4)\n",
      "Requirement already satisfied: opencv-python-headless>=4.5.5.64 in c:\\users\\ghadf\\vscode_projects\\venv_projects\\pytorch\\yolo_exploration\\.venv\\lib\\site-packages (from supervision) (4.8.0.74)\n",
      "Requirement already satisfied: pillow>=9.4 in c:\\users\\ghadf\\vscode_projects\\venv_projects\\pytorch\\yolo_exploration\\.venv\\lib\\site-packages (from supervision) (10.3.0)\n",
      "Requirement already satisfied: pyyaml>=5.3 in c:\\users\\ghadf\\vscode_projects\\venv_projects\\pytorch\\yolo_exploration\\.venv\\lib\\site-packages (from supervision) (6.0.1)\n",
      "Requirement already satisfied: scipy<2.0.0,>=1.10.0 in c:\\users\\ghadf\\vscode_projects\\venv_projects\\pytorch\\yolo_exploration\\.venv\\lib\\site-packages (from supervision) (1.13.1)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in c:\\users\\ghadf\\vscode_projects\\venv_projects\\pytorch\\yolo_exploration\\.venv\\lib\\site-packages (from matplotlib>=3.6.0->supervision) (1.2.1)\n",
      "Requirement already satisfied: cycler>=0.10 in c:\\users\\ghadf\\vscode_projects\\venv_projects\\pytorch\\yolo_exploration\\.venv\\lib\\site-packages (from matplotlib>=3.6.0->supervision) (0.10.0)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in c:\\users\\ghadf\\vscode_projects\\venv_projects\\pytorch\\yolo_exploration\\.venv\\lib\\site-packages (from matplotlib>=3.6.0->supervision) (4.52.1)\n",
      "Requirement already satisfied: kiwisolver>=1.3.1 in c:\\users\\ghadf\\vscode_projects\\venv_projects\\pytorch\\yolo_exploration\\.venv\\lib\\site-packages (from matplotlib>=3.6.0->supervision) (1.4.5)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\users\\ghadf\\vscode_projects\\venv_projects\\pytorch\\yolo_exploration\\.venv\\lib\\site-packages (from matplotlib>=3.6.0->supervision) (24.0)\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in c:\\users\\ghadf\\vscode_projects\\venv_projects\\pytorch\\yolo_exploration\\.venv\\lib\\site-packages (from matplotlib>=3.6.0->supervision) (3.1.2)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in c:\\users\\ghadf\\vscode_projects\\venv_projects\\pytorch\\yolo_exploration\\.venv\\lib\\site-packages (from matplotlib>=3.6.0->supervision) (2.9.0.post0)\n",
      "Requirement already satisfied: six in c:\\users\\ghadf\\vscode_projects\\venv_projects\\pytorch\\yolo_exploration\\.venv\\lib\\site-packages (from cycler>=0.10->matplotlib>=3.6.0->supervision) (1.16.0)\n",
      "Requirement already satisfied: roboflow in c:\\users\\ghadf\\vscode_projects\\venv_projects\\pytorch\\yolo_exploration\\.venv\\lib\\site-packages (1.1.30)\n",
      "Requirement already satisfied: certifi==2023.7.22 in c:\\users\\ghadf\\vscode_projects\\venv_projects\\pytorch\\yolo_exploration\\.venv\\lib\\site-packages (from roboflow) (2023.7.22)\n",
      "Requirement already satisfied: chardet==4.0.0 in c:\\users\\ghadf\\vscode_projects\\venv_projects\\pytorch\\yolo_exploration\\.venv\\lib\\site-packages (from roboflow) (4.0.0)\n",
      "Requirement already satisfied: cycler==0.10.0 in c:\\users\\ghadf\\vscode_projects\\venv_projects\\pytorch\\yolo_exploration\\.venv\\lib\\site-packages (from roboflow) (0.10.0)\n",
      "Requirement already satisfied: idna==2.10 in c:\\users\\ghadf\\vscode_projects\\venv_projects\\pytorch\\yolo_exploration\\.venv\\lib\\site-packages (from roboflow) (2.10)\n",
      "Requirement already satisfied: kiwisolver>=1.3.1 in c:\\users\\ghadf\\vscode_projects\\venv_projects\\pytorch\\yolo_exploration\\.venv\\lib\\site-packages (from roboflow) (1.4.5)\n",
      "Requirement already satisfied: matplotlib in c:\\users\\ghadf\\vscode_projects\\venv_projects\\pytorch\\yolo_exploration\\.venv\\lib\\site-packages (from roboflow) (3.9.0)\n",
      "Requirement already satisfied: numpy>=1.18.5 in c:\\users\\ghadf\\vscode_projects\\venv_projects\\pytorch\\yolo_exploration\\.venv\\lib\\site-packages (from roboflow) (1.26.4)\n",
      "Requirement already satisfied: opencv-python-headless==4.8.0.74 in c:\\users\\ghadf\\vscode_projects\\venv_projects\\pytorch\\yolo_exploration\\.venv\\lib\\site-packages (from roboflow) (4.8.0.74)\n",
      "Requirement already satisfied: Pillow>=7.1.2 in c:\\users\\ghadf\\vscode_projects\\venv_projects\\pytorch\\yolo_exploration\\.venv\\lib\\site-packages (from roboflow) (10.3.0)\n",
      "Requirement already satisfied: python-dateutil in c:\\users\\ghadf\\vscode_projects\\venv_projects\\pytorch\\yolo_exploration\\.venv\\lib\\site-packages (from roboflow) (2.9.0.post0)\n",
      "Requirement already satisfied: python-dotenv in c:\\users\\ghadf\\vscode_projects\\venv_projects\\pytorch\\yolo_exploration\\.venv\\lib\\site-packages (from roboflow) (1.0.1)\n",
      "Requirement already satisfied: requests in c:\\users\\ghadf\\vscode_projects\\venv_projects\\pytorch\\yolo_exploration\\.venv\\lib\\site-packages (from roboflow) (2.32.2)\n",
      "Requirement already satisfied: six in c:\\users\\ghadf\\vscode_projects\\venv_projects\\pytorch\\yolo_exploration\\.venv\\lib\\site-packages (from roboflow) (1.16.0)\n",
      "Requirement already satisfied: urllib3>=1.26.6 in c:\\users\\ghadf\\vscode_projects\\venv_projects\\pytorch\\yolo_exploration\\.venv\\lib\\site-packages (from roboflow) (2.2.1)\n",
      "Requirement already satisfied: tqdm>=4.41.0 in c:\\users\\ghadf\\vscode_projects\\venv_projects\\pytorch\\yolo_exploration\\.venv\\lib\\site-packages (from roboflow) (4.66.4)\n",
      "Requirement already satisfied: PyYAML>=5.3.1 in c:\\users\\ghadf\\vscode_projects\\venv_projects\\pytorch\\yolo_exploration\\.venv\\lib\\site-packages (from roboflow) (6.0.1)\n",
      "Requirement already satisfied: requests-toolbelt in c:\\users\\ghadf\\vscode_projects\\venv_projects\\pytorch\\yolo_exploration\\.venv\\lib\\site-packages (from roboflow) (1.0.0)\n",
      "Requirement already satisfied: python-magic in c:\\users\\ghadf\\vscode_projects\\venv_projects\\pytorch\\yolo_exploration\\.venv\\lib\\site-packages (from roboflow) (0.4.27)\n",
      "Requirement already satisfied: colorama in c:\\users\\ghadf\\vscode_projects\\venv_projects\\pytorch\\yolo_exploration\\.venv\\lib\\site-packages (from tqdm>=4.41.0->roboflow) (0.4.6)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in c:\\users\\ghadf\\vscode_projects\\venv_projects\\pytorch\\yolo_exploration\\.venv\\lib\\site-packages (from matplotlib->roboflow) (1.2.1)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in c:\\users\\ghadf\\vscode_projects\\venv_projects\\pytorch\\yolo_exploration\\.venv\\lib\\site-packages (from matplotlib->roboflow) (4.52.1)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\users\\ghadf\\vscode_projects\\venv_projects\\pytorch\\yolo_exploration\\.venv\\lib\\site-packages (from matplotlib->roboflow) (24.0)\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in c:\\users\\ghadf\\vscode_projects\\venv_projects\\pytorch\\yolo_exploration\\.venv\\lib\\site-packages (from matplotlib->roboflow) (3.1.2)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\ghadf\\vscode_projects\\venv_projects\\pytorch\\yolo_exploration\\.venv\\lib\\site-packages (from requests->roboflow) (3.3.2)\n",
      "Setup and installation complete.\n",
      "File already exists: weights\\yolov10n.pt\n",
      "File already exists: weights\\yolov10s.pt\n",
      "File already exists: weights\\yolov10m.pt\n",
      "File already exists: weights\\yolov10b.pt\n",
      "File already exists: weights\\yolov10x.pt\n",
      "File already exists: weights\\yolov10l.pt\n",
      "2.3.1+cu121\n",
      "CUDA available:  True\n",
      "Using device: cuda\n",
      "yolov10 preset classes =  {0: '0', 1: '1', 2: '2', 3: '3', 4: '4', 5: '5', 6: '6', 7: '7', 8: '8', 9: '9', 10: '10', 11: '11', 12: '12', 13: '13', 14: '14', 15: '15', 16: '16', 17: '17', 18: '18', 19: '19', 20: '20', 21: '21', 22: '22', 23: '23', 24: '24', 25: '25', 26: '26', 27: '27', 28: '28', 29: '29', 30: '30', 31: '31', 32: '32', 33: '33', 34: '34', 35: '35', 36: '36', 37: '37', 38: '38', 39: '39', 40: '40', 41: '41', 42: '42', 43: '43', 44: '44', 45: '45', 46: '46', 47: '47', 48: '48', 49: '49', 50: '50', 51: '51', 52: '52', 53: '53', 54: '54', 55: '55', 56: '56', 57: '57', 58: '58', 59: '59', 60: '60', 61: '61', 62: '62', 63: '63', 64: '64', 65: '65', 66: '66', 67: '67', 68: '68', 69: '69', 70: '70', 71: '71', 72: '72', 73: '73', 74: '74', 75: '75', 76: '76', 77: '77', 78: '78', 79: '79'}\n",
      "upload and label your dataset, and get an API KEY here: https://app.roboflow.com/?model=undefined&ref=undefined\n",
      "\n",
      "loading Roboflow workspace...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  Running command git clone --filter=blob:none --quiet https://github.com/THU-MIG/yolov10.git 'C:\\Users\\ghadf\\AppData\\Local\\Temp\\pip-req-build-k47tvxov'\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\ghadf\\vscode_projects\\venv_projects\\Pytorch\\YOLO_exploration\\main.py\", line 48, in <module>\n",
      "    main(args)\n",
      "  File \"c:\\Users\\ghadf\\vscode_projects\\venv_projects\\Pytorch\\YOLO_exploration\\main.py\", line 24, in main\n",
      "    dataset_location, data_yaml_path, class_names = download_dataset()\n",
      "                                                    ^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\ghadf\\vscode_projects\\venv_projects\\Pytorch\\YOLO_exploration\\modularized\\download_dataset.py\", line 7, in download_dataset\n",
      "    project = rf.workspace(\"basketball-formations\").project(\"basketball-and-hoop-7xk0h\")\n",
      "              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\ghadf\\vscode_projects\\venv_projects\\Pytorch\\YOLO_exploration\\.venv\\Lib\\site-packages\\roboflow\\__init__.py\", line 259, in workspace\n",
      "    list_projects = rfapi.get_workspace(api_key, the_workspace)\n",
      "                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\ghadf\\vscode_projects\\venv_projects\\Pytorch\\YOLO_exploration\\.venv\\Lib\\site-packages\\roboflow\\adapters\\rfapi.py\", line 24, in get_workspace\n",
      "    raise RoboflowError(response.text)\n",
      "roboflow.adapters.rfapi.RoboflowError: {\n",
      "    \"error\": {\n",
      "        \"message\": \"This API key does not exist (or has been revoked).\",\n",
      "        \"status\": 401,\n",
      "        \"type\": \"OAuthException\",\n",
      "        \"hint\": \"You may retrieve your API key via the Roboflow Dashboard. Go to Account > Roboflow Keys to retrieve yours.\",\n",
      "        \"key\": \"YOUR_API_KEY\"\n",
      "    }\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "#Example usage\n",
    "\n",
    "\n",
    "!python main.py --epochs 5 --batch_size 16 --image_path path/to/your_image.png --yt_video_url https://www.youtube.com/watch?v=example_video_url\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
