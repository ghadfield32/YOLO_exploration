{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ghadfield32/YOLO_exploration/blob/main/Yolov8_autodistil_training.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8tq5Bu0uksID",
        "outputId": "c82f2965-d0c6-402c-d10d-b6bcc8875ec6"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Ultralytics YOLOv8.0.134 ðŸš€ Python-3.10.12 torch-2.0.1+cu118 CUDA:0 (Tesla T4, 15102MiB)\n",
            "Setup complete âœ… (2 CPUs, 12.7 GB RAM, 33.1/78.2 GB disk)\n"
          ]
        }
      ],
      "source": [
        "# Pip install method (recommended)\n",
        "!pip install ultralytics==8.0.134  # updated version\n",
        "\n",
        "\n",
        "from IPython import display\n",
        "display.clear_output()\n",
        "\n",
        "import ultralytics\n",
        "ultralytics.checks()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RDvKM5W3ku3D"
      },
      "outputs": [],
      "source": [
        "from ultralytics import YOLO\n",
        "\n",
        "from IPython.display import display, Image"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Ix2ldb6zoVu-"
      },
      "outputs": [],
      "source": [
        "!pip install -q \\\n",
        "autodistill \\\n",
        "autodistill-grounded-sam \\\n",
        "autodistill-yolov8 \\\n",
        "roboflow \\\n",
        "supervision==0.9.0"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Pcqft88aocyw",
        "outputId": "df34ddef-59ed-45d2-db46-862565b7b935"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "HOME = os.getcwd()\n",
        "print(HOME)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nKburxUfk9sU",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1be167bd-72d7-4b80-ca48-39d3e2625d49"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "mkdir: cannot create directory â€˜/content/imagesâ€™: File exists\n"
          ]
        }
      ],
      "source": [
        "!mkdir {HOME}/images"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hgjQUQPFlCjT",
        "outputId": "b1e2e3b3-63c4-42d3-b3b2-97a5f239171c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "You are already logged into Roboflow. To make a different login, run roboflow.login(force=True).\n",
            "loading Roboflow workspace...\n",
            "loading Roboflow project...\n",
            "Downloading Dataset Version Zip in TACO:-Trash-Annotations-in-Context-Dataset-16 to yolov8: 100% [340367252 / 340367252] bytes\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Extracting Dataset Version Zip to TACO:-Trash-Annotations-in-Context-Dataset-16 in yolov8:: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 7204/7204 [00:02<00:00, 2497.16it/s]\n"
          ]
        }
      ],
      "source": [
        "\n",
        " import roboflow\n",
        "\n",
        " roboflow.login()\n",
        "#try this for 3-2 def: https://universe.roboflow.com/basketball-formations/3_2_d\n",
        " dataset = roboflow.download_dataset(dataset_url=\"https://universe.roboflow.com/mohamed-traore-2ekkp/taco-trash-annotations-in-context/model/16\", model_format=\"yolov8\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6vnNpbmuqBX7",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 340
        },
        "outputId": "ed74097a-39dd-4054-ef05-3639f8584c4c"
      },
      "outputs": [
        {
          "output_type": "error",
          "ename": "Error",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mError\u001b[0m                                     Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-7-c43f5c49f01a>\u001b[0m in \u001b[0;36m<cell line: 10>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     13\u001b[0m     \u001b[0;31m# List all files in the source directory and move each one to the destination directory\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mfile_name\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlistdir\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msrc_dir\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 15\u001b[0;31m         \u001b[0mshutil\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmove\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msrc_dir\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfile_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdest_dir\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/lib/python3.10/shutil.py\u001b[0m in \u001b[0;36mmove\u001b[0;34m(src, dst, copy_function)\u001b[0m\n\u001b[1;32m    812\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    813\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexists\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mreal_dst\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 814\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Destination path '%s' already exists\"\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0mreal_dst\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    815\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    816\u001b[0m         \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrename\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msrc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreal_dst\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mError\u001b[0m: Destination path '/content/images/images' already exists"
          ]
        }
      ],
      "source": [
        "#inputting dataset into the images directory\n",
        "import shutil\n",
        "import os\n",
        "\n",
        "# Define the correct source directory\n",
        "src_dir = \"/content/TACO:-Trash-Annotations-in-Context-Dataset-16/train\"\n",
        "dest_dir = os.path.join(HOME, \"images\")\n",
        "\n",
        "# Check if the source directory exists, if not print an error message\n",
        "if not os.path.exists(src_dir):\n",
        "    print(f\"Source directory '{src_dir}' does not exist!\")\n",
        "else:\n",
        "    # List all files in the source directory and move each one to the destination directory\n",
        "    for file_name in os.listdir(src_dir):\n",
        "        shutil.move(os.path.join(src_dir, file_name), dest_dir)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "67GJGitertvq"
      },
      "outputs": [],
      "source": [
        "!mkdir {HOME}/videos\n",
        "%cd {HOME}/videos\n",
        "\n",
        "# download zip file containing videos\n",
        "!wget --load-cookies /tmp/cookies.txt \"https://docs.google.com/uc?export=download&confirm=$(wget --quiet --save-cookies /tmp/cookies.txt --keep-session-cookies --no-check-certificate 'https://docs.google.com/uc?export=download&id=1wnW7v6UTJZTAcOQj0416ZbQF8b7yO6Pt' -O- | sed -rn 's/.*confirm=([0-9A-Za-z_]+).*/\\1\\n/p')&id=1wnW7v6UTJZTAcOQj0416ZbQF8b7yO6Pt\" -O milk.zip && rm -rf /tmp/cookies.txt\n",
        "\n",
        " #unzip videos\n",
        "!unzip milk.zip"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "VIDEO_DIR_PATH = f\"{HOME}/videos\"\n",
        "IMAGE_DIR_PATH = f\"{HOME}/images\"\n",
        "FRAME_STRIDE = 10"
      ],
      "metadata": {
        "id": "kPpD9bLYdkwu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Split video into Test and Train Videos\n",
        "import supervision as sv\n",
        "from tqdm.notebook import tqdm\n",
        "\n",
        "video_paths = sv.list_files_with_extensions(\n",
        "    directory=VIDEO_DIR_PATH,\n",
        "    extensions=[\"mov\", \"mp4\"])\n",
        "\n",
        "TEST_VIDEO_PATHS, TRAIN_VIDEO_PATHS = video_paths[:2], video_paths[2:]\n",
        "\n",
        "for video_path in tqdm(TRAIN_VIDEO_PATHS):\n",
        "    video_name = video_path.stem\n",
        "    image_name_pattern = video_name + \"-{:05d}.png\"\n",
        "    with sv.ImageSink(target_dir_path=IMAGE_DIR_PATH, image_name_pattern=image_name_pattern) as sink:\n",
        "        for image in sv.get_video_frames_generator(source_path=str(video_path), stride=FRAME_STRIDE):\n",
        "            sink.save_image(image=image)"
      ],
      "metadata": {
        "id": "1K9XWO3gdvC4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import supervision as sv\n",
        "\n",
        "image_paths = sv.list_files_with_extensions(\n",
        "    directory=IMAGE_DIR_PATH,\n",
        "    extensions=[\"png\", \"jpg\", \"jpg\"])\n",
        "\n",
        "print('image count:', len(image_paths))"
      ],
      "metadata": {
        "id": "THCmD3FXdyDq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#We can also plot sample of our image dataset.\n",
        "IMAGE_DIR_PATH = f\"{HOME}/images\"\n",
        "SAMPLE_SIZE = 16\n",
        "SAMPLE_GRID_SIZE = (4, 4)\n",
        "SAMPLE_PLOT_SIZE = (16, 16)"
      ],
      "metadata": {
        "id": "sGW6mx4pd4Wq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import cv2\n",
        "import supervision as sv\n",
        "\n",
        "titles = [\n",
        "    image_path.stem\n",
        "    for image_path\n",
        "    in image_paths[:SAMPLE_SIZE]]\n",
        "images = [\n",
        "    cv2.imread(str(image_path))\n",
        "    for image_path\n",
        "    in image_paths[:SAMPLE_SIZE]]\n",
        "\n",
        "sv.plot_images_grid(images=images, titles=titles, grid_size=SAMPLE_GRID_SIZE, size=SAMPLE_PLOT_SIZE)"
      ],
      "metadata": {
        "id": "4imWbv39eVDM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from autodistill.detection import CaptionOntology\n",
        "#Ontology - an Ontology defines how your Base Model is prompted, what your Dataset will describe, and what your Target Model will predict.\n",
        "ontology=CaptionOntology({\n",
        "    \"milk bottle\": \"bottle\",\n",
        "    \"blue cap\": \"cap\",\n",
        "    #\"red button\": \"button\"\n",
        "})"
      ],
      "metadata": {
        "id": "88oxHR0ieWe1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "DATASET_DIR_PATH = f\"{HOME}/dataset\""
      ],
      "metadata": {
        "id": "Tam1zSo2epGN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from autodistill_grounded_sam import GroundedSAM\n",
        "\n",
        "base_model = GroundedSAM(ontology=ontology)\n",
        "dataset = base_model.label(\n",
        "    input_folder=IMAGE_DIR_PATH,\n",
        "    extension=\".png\",\n",
        "    output_folder=DATASET_DIR_PATH)"
      ],
      "metadata": {
        "id": "r6t4zPh7exU8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "ANNOTATIONS_DIRECTORY_PATH = f\"{HOME}/dataset/train/labels\"\n",
        "IMAGES_DIRECTORY_PATH = f\"{HOME}/dataset/train/images\"\n",
        "DATA_YAML_PATH = f\"{HOME}/dataset/data.yaml\""
      ],
      "metadata": {
        "id": "7IfKWLR2ez0v"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import supervision as sv\n",
        "\n",
        "dataset = sv.DetectionDataset.from_yolo(\n",
        "    images_directory_path=IMAGES_DIRECTORY_PATH,\n",
        "    annotations_directory_path=ANNOTATIONS_DIRECTORY_PATH,\n",
        "    data_yaml_path=DATA_YAML_PATH)\n",
        "\n",
        "len(dataset)"
      ],
      "metadata": {
        "id": "yvcIOpp0fC6w"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import supervision as sv\n",
        "\n",
        "image_names = list(dataset.images.keys())[:SAMPLE_SIZE]\n",
        "\n",
        "mask_annotator = sv.MaskAnnotator()\n",
        "box_annotator = sv.BoxAnnotator()\n",
        "\n",
        "images = []\n",
        "for image_name in image_names:\n",
        "    image = dataset.images[image_name]\n",
        "    annotations = dataset.annotations[image_name]\n",
        "    labels = [\n",
        "        dataset.classes[class_id]\n",
        "        for class_id\n",
        "        in annotations.class_id]\n",
        "    annotates_image = mask_annotator.annotate(\n",
        "        scene=image.copy(),\n",
        "        detections=annotations)\n",
        "    annotates_image = box_annotator.annotate(\n",
        "        scene=annotates_image,\n",
        "        detections=annotations,\n",
        "        labels=labels)\n",
        "    images.append(annotates_image)\n",
        "\n",
        "sv.plot_images_grid(\n",
        "    images=images,\n",
        "    titles=image_names,\n",
        "    grid_size=SAMPLE_GRID_SIZE,\n",
        "    size=SAMPLE_PLOT_SIZE)"
      ],
      "metadata": {
        "id": "lCz_kzedfGPz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%cd {HOME}\n",
        "\n",
        "from autodistill_yolov8 import YOLOv8\n",
        "\n",
        "target_model = YOLOv8(\"yolov8n.pt\")\n",
        "target_model.train(DATA_YAML_PATH, epochs=50)"
      ],
      "metadata": {
        "id": "LJO-b2tGfISb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!ls {HOME}/runs/detect/train/"
      ],
      "metadata": {
        "id": "m0omug6BfLVQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%cd {HOME}\n",
        "\n",
        "from IPython.display import Image\n",
        "\n",
        "Image(filename=f'{HOME}/runs/detect/train/confusion_matrix.png', width=600)"
      ],
      "metadata": {
        "id": "woh1OJY6fMdF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%cd {HOME}\n",
        "\n",
        "from IPython.display import Image\n",
        "\n",
        "Image(filename=f'{HOME}/runs/detect/train/results.png', width=600)"
      ],
      "metadata": {
        "id": "gLMbgdXrfO6m"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%cd {HOME}\n",
        "\n",
        "from IPython.display import Image\n",
        "\n",
        "Image(filename=f'{HOME}/runs/detect/train/val_batch0_pred.jpg', width=600)"
      ],
      "metadata": {
        "id": "gF4B1gssfQyA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "INPUT_VIDEO_PATH = TEST_VIDEO_PATHS[0]\n",
        "OUTPUT_VIDEO_PATH = f\"{HOME}/output.mp4\"\n",
        "TRAINED_MODEL_PATH = f\"{HOME}/runs/detect/train/weights/best.pt\""
      ],
      "metadata": {
        "id": "_jpmCsS_fSrK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!yolo predict model={TRAINED_MODEL_PATH} source={INPUT_VIDEO_PATH}"
      ],
      "metadata": {
        "id": "prtAfsGrfaBZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "hTnj1baofcT9"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "authorship_tag": "ABX9TyPv0C5rkbn0WuF4lWpzbVOl",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}